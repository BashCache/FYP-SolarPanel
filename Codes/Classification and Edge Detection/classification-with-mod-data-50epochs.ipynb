{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport random\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport glob\nimport os\nimport cv2\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom numpy import expand_dims, argmax\nimport keras\nimport tensorflow as tf\nfrom keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications import resnet50, inception_v3, vgg16\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow import keras\nfrom keras import optimizers\nfrom keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D, BatchNormalization\nfrom tensorflow.keras.optimizers import SGD, Adam, RMSprop\nfrom keras.models import Sequential, load_model, Model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.utils import to_categorical\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom tensorflow.keras.applications import EfficientNetB0, EfficientNetB4\nfrom sklearn.metrics import roc_curve, auc, accuracy_score\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.preprocessing import label_binarize\n\nscaler = MinMaxScaler()\n\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-13T17:04:50.003804Z","iopub.execute_input":"2022-04-13T17:04:50.004144Z","iopub.status.idle":"2022-04-13T17:04:56.605935Z","shell.execute_reply.started":"2022-04-13T17:04:50.004038Z","shell.execute_reply":"2022-04-13T17:04:56.605125Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### **Reading data in proper format**","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/csv-mod-dataset/Module_1 - Rooftop_Detectection_Mod_Dataset.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:04:56.607503Z","iopub.execute_input":"2022-04-13T17:04:56.607753Z","iopub.status.idle":"2022-04-13T17:04:56.633531Z","shell.execute_reply.started":"2022-04-13T17:04:56.607718Z","shell.execute_reply":"2022-04-13T17:04:56.632777Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### **Label Encoding**","metadata":{}},{"cell_type":"code","source":"label_encoder = preprocessing.LabelEncoder()\ndf['Type_LabelEncoded'] = label_encoder.fit_transform(df['Type'])\n\n# Complex -> 0\n# Flat -> 1\n# Gable -> 2\n# Hip -> 3\n# Pyramid -> 4 ","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:04:56.634950Z","iopub.execute_input":"2022-04-13T17:04:56.635211Z","iopub.status.idle":"2022-04-13T17:04:56.647401Z","shell.execute_reply.started":"2022-04-13T17:04:56.635177Z","shell.execute_reply":"2022-04-13T17:04:56.646501Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df['Type'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:04:56.650269Z","iopub.execute_input":"2022-04-13T17:04:56.650576Z","iopub.status.idle":"2022-04-13T17:04:56.665432Z","shell.execute_reply.started":"2022-04-13T17:04:56.650539Z","shell.execute_reply":"2022-04-13T17:04:56.664646Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"ax = df['Type'].value_counts().plot(kind = 'bar',\n                                    figsize = (14,8),\n                                    title = \"No of rooftops for each type\",\n                                    color = 'orange')\nax.set_xlabel(\"Rooftop Type\")\nax.set_ylabel(\"Frequency\")","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:04:56.667223Z","iopub.execute_input":"2022-04-13T17:04:56.667707Z","iopub.status.idle":"2022-04-13T17:04:56.927683Z","shell.execute_reply.started":"2022-04-13T17:04:56.667674Z","shell.execute_reply":"2022-04-13T17:04:56.926889Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### **Storing image names in list**","metadata":{}},{"cell_type":"code","source":"path = '../input/rooftype-dataset-mod/rooftype-dataset-mod-jpg'\nimage_names = []\nlabels = []\n\nfor img in glob.glob(os.path.join(path, 'Flat-jpg', '*')):\n    image_names.append(img)\n    labels.append(0)\n    \nfor img in glob.glob(os.path.join(path, 'Gable-jpg', '*')):\n    image_names.append(img)\n    labels.append(1)\n    \nfor img in glob.glob(os.path.join(path, 'Hip-jpg', '*')):\n    image_names.append(img)\n    labels.append(2)\n\nprint(\"No of images: {0}\".format(len(image_names)))\nprint(\"Labels: {0}\".format(len(labels)))","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:04:56.929006Z","iopub.execute_input":"2022-04-13T17:04:56.929686Z","iopub.status.idle":"2022-04-13T17:04:57.253279Z","shell.execute_reply.started":"2022-04-13T17:04:56.929648Z","shell.execute_reply":"2022-04-13T17:04:57.252554Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### **Shuffle list**","metadata":{}},{"cell_type":"code","source":"zipped_list = list(zip(image_names, labels))\nrandom.shuffle(zipped_list)\nimage_names, labels = zip(*zipped_list)\nimage_names, labels = list(image_names), list(labels)\n\nprint(image_names)\nprint(labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:04:57.255089Z","iopub.execute_input":"2022-04-13T17:04:57.255530Z","iopub.status.idle":"2022-04-13T17:04:57.268515Z","shell.execute_reply.started":"2022-04-13T17:04:57.255482Z","shell.execute_reply":"2022-04-13T17:04:57.265859Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### **Pre-processing**","metadata":{}},{"cell_type":"code","source":"X = []\nY = []\nfor img in image_names:\n    img = cv2.imread(img, cv2.IMREAD_COLOR)\n    resized_img = cv2.resize(img, (256, 256), interpolation = cv2.INTER_CUBIC)\n    X.append(resized_img)\n\nY = labels","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:04:57.270399Z","iopub.execute_input":"2022-04-13T17:04:57.270692Z","iopub.status.idle":"2022-04-13T17:05:25.013333Z","shell.execute_reply.started":"2022-04-13T17:04:57.270656Z","shell.execute_reply":"2022-04-13T17:05:25.012584Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"X = np.array(X)\nY = np.array(Y)\n\nprint(X.shape, Y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:05:25.014865Z","iopub.execute_input":"2022-04-13T17:05:25.015288Z","iopub.status.idle":"2022-04-13T17:05:25.086750Z","shell.execute_reply.started":"2022-04-13T17:05:25.015252Z","shell.execute_reply":"2022-04-13T17:05:25.085292Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X = X.astype('float32')\nX /= 255.\nY = Y.reshape(Y.shape[0],1)\nprint(X.shape, Y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:05:25.089845Z","iopub.execute_input":"2022-04-13T17:05:25.090038Z","iopub.status.idle":"2022-04-13T17:05:25.385551Z","shell.execute_reply.started":"2022-04-13T17:05:25.090014Z","shell.execute_reply":"2022-04-13T17:05:25.384800Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### **Train-test split**","metadata":{}},{"cell_type":"code","source":"train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size = 0.04)\ntrain_X, val_X, train_Y, val_Y = train_test_split(train_X, train_Y, test_size = 0.05)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:05:25.386815Z","iopub.execute_input":"2022-04-13T17:05:25.387100Z","iopub.status.idle":"2022-04-13T17:05:25.873183Z","shell.execute_reply.started":"2022-04-13T17:05:25.387056Z","shell.execute_reply":"2022-04-13T17:05:25.872404Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(\"Train X: {0}, Train Y: {1}\".format(train_X.shape, train_Y.shape))\nprint(\"Val X: {0}, Val Y: {1}\".format(val_X.shape, val_Y.shape))\nprint(\"Test X: {0}, Test Y: {1}\".format(test_X.shape, test_Y.shape))","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:05:25.874547Z","iopub.execute_input":"2022-04-13T17:05:25.874805Z","iopub.status.idle":"2022-04-13T17:05:25.883500Z","shell.execute_reply.started":"2022-04-13T17:05:25.874771Z","shell.execute_reply":"2022-04-13T17:05:25.882775Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### **One-hot encoding**","metadata":{}},{"cell_type":"code","source":"train_Y = to_categorical(train_Y, num_classes = 3)\nval_Y = to_categorical(val_Y, num_classes = 3)\ntest_Y = to_categorical(test_Y, num_classes = 3)\n\nprint(\"Shape: {0}, {1}, {2}\".format(train_Y.shape, val_Y.shape, test_Y.shape))","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:05:25.884966Z","iopub.execute_input":"2022-04-13T17:05:25.885372Z","iopub.status.idle":"2022-04-13T17:05:25.893984Z","shell.execute_reply.started":"2022-04-13T17:05:25.885331Z","shell.execute_reply":"2022-04-13T17:05:25.893114Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### **Plotting images**","metadata":{}},{"cell_type":"code","source":"rows = 36\ncolumns = 3\ncount = 1\nfor image_number in range(0,50, 3):\n\n    fig = plt.figure(figsize=(15,15))\n\n    fig.add_subplot(rows, columns, count)\n    plt.subplot(1,3,1)\n    plt.imshow(np.squeeze(train_X[image_number:image_number+1]))\n\n    fig.add_subplot(rows, columns, count+1)\n    plt.subplot(1,3,2)\n    plt.imshow(np.squeeze(train_X[image_number+1:image_number+2]))\n\n    fig.add_subplot(rows, columns, count+2)\n    plt.subplot(1,3,3)\n    plt.imshow(np.squeeze(train_X[image_number+2:image_number+3]))\n\n    count += 3\n","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:05:25.895319Z","iopub.execute_input":"2022-04-13T17:05:25.895667Z","iopub.status.idle":"2022-04-13T17:05:36.001148Z","shell.execute_reply.started":"2022-04-13T17:05:25.895628Z","shell.execute_reply":"2022-04-13T17:05:36.000387Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### **Data Augmentation**","metadata":{}},{"cell_type":"code","source":"data_generation = ImageDataGenerator(\n    rotation_range = 7,  # randomly rotate images in the range (degrees, 0 to 180)\n    width_shift_range = 0.10,  # randomly shift images horizontally (fraction of total width)\n    height_shift_range = 0.10,  # randomly shift images vertically (fraction of total height)\n    horizontal_flip = True,  # randomly flip images\n    vertical_flip = True,   # randomly flip images\n    fill_mode = 'reflect')  \ndata_generation.fit(train_X)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:05:36.002417Z","iopub.execute_input":"2022-04-13T17:05:36.002745Z","iopub.status.idle":"2022-04-13T17:05:36.303390Z","shell.execute_reply.started":"2022-04-13T17:05:36.002708Z","shell.execute_reply":"2022-04-13T17:05:36.302625Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### **Plot graphs**","metadata":{}},{"cell_type":"code","source":"def plot_accuracy_loss(history):\n    \"\"\"\n        Plot the accuracy and the loss during the training of the nn.\n    \"\"\"\n    fig = plt.figure(figsize=(10,5))\n\n    # Plot accuracy\n    plt.subplot(221)\n    plt.plot(history.history['acc'], label = \"acc\")\n    plt.plot(history.history['val_acc'], label = \"val_acc\")\n    plt.title(\"train_acc vs val_acc\")\n    plt.ylabel(\"accuracy\")\n    plt.xlabel(\"epochs\")\n    plt.legend()\n\n    # Plot loss function\n    plt.subplot(222)\n    plt.plot(history.history['loss'], label = \"loss\")\n    plt.plot(history.history['val_loss'], label = \"val_loss\")\n    plt.title(\"train_loss vs val_loss\")\n    plt.ylabel(\"loss\")\n    plt.xlabel(\"epochs\")\n\n    plt.legend()\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:05:36.304630Z","iopub.execute_input":"2022-04-13T17:05:36.304882Z","iopub.status.idle":"2022-04-13T17:05:36.312722Z","shell.execute_reply.started":"2022-04-13T17:05:36.304849Z","shell.execute_reply":"2022-04-13T17:05:36.312022Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### **Make Predictions**","metadata":{}},{"cell_type":"code","source":"def make_predictions(model, test_X, test_Y):\n    test_loss = model.evaluate(test_X, test_Y)\n    predictions = model.predict(test_X)\n    pred_labels = np.argmax(predictions, axis = 1)\n    test_labels = np.argmax(test_Y, axis = 1)\n    return pred_labels, test_labels","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:05:36.314153Z","iopub.execute_input":"2022-04-13T17:05:36.314619Z","iopub.status.idle":"2022-04-13T17:05:36.323708Z","shell.execute_reply.started":"2022-04-13T17:05:36.314579Z","shell.execute_reply":"2022-04-13T17:05:36.322952Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### **Plot Confusion Matrix**","metadata":{}},{"cell_type":"code","source":"def plot_confusion_matrix(test_labels, pred_labels):\n    Y_test_actual = test_labels\n    Y_test_pred = pred_labels\n    confusion_mtx = confusion_matrix(Y_test_actual, Y_test_pred) \n\n    f,ax = plt.subplots(figsize = (8, 8))\n    sns.heatmap(confusion_mtx, annot = True, linewidths = 0.01, cmap = \"Greens\", linecolor = \"gray\", fmt = '.1f', ax = ax)\n    plt.xlabel(\"Predicted Label\")\n    plt.ylabel(\"True Label\")\n    plt.title(\"Confusion Matrix\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:05:36.325124Z","iopub.execute_input":"2022-04-13T17:05:36.325402Z","iopub.status.idle":"2022-04-13T17:05:36.334583Z","shell.execute_reply.started":"2022-04-13T17:05:36.325365Z","shell.execute_reply":"2022-04-13T17:05:36.333742Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"### **Classification Report**","metadata":{}},{"cell_type":"code","source":"def print_classification_report(test_labels, pred_labels):\n    print(\"Classification Report: \")\n    print(classification_report(test_labels, pred_labels))","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:05:36.337026Z","iopub.execute_input":"2022-04-13T17:05:36.337539Z","iopub.status.idle":"2022-04-13T17:05:36.346666Z","shell.execute_reply.started":"2022-04-13T17:05:36.337501Z","shell.execute_reply":"2022-04-13T17:05:36.345847Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### **Plot AUC-ROC Graph**","metadata":{}},{"cell_type":"code","source":"def plot_AUC_ROC(model, test_X, test_Y):\n\n    predictions = model.predict(test_X) \n    print(predictions)\n\n    # Compute ROC curve and ROC area for each class\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    for i in range(3):\n        fpr[i], tpr[i], _ = roc_curve(test_Y[:, i], predictions[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n    print(\"ROC_AUC score for 3 models: {0}\".format(roc_auc))\n\n    # Plot of a ROC curve for a specific class\n    for i in range(3):\n        plt.figure()\n        plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n        plt.plot([0, 1], [0, 1], 'k--')\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('Receiver operating characteristic example')\n        plt.legend(loc=\"lower right\")\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:05:36.349889Z","iopub.execute_input":"2022-04-13T17:05:36.350134Z","iopub.status.idle":"2022-04-13T17:05:36.361629Z","shell.execute_reply.started":"2022-04-13T17:05:36.350105Z","shell.execute_reply":"2022-04-13T17:05:36.360757Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### **Validating our model on PotsDam dataset**","metadata":{}},{"cell_type":"code","source":"potsdam_image_paths_list = []\npotsdam_image_labels = []\npotsdam_image_path_flat = '../input/potsdam-mini/potsdam-mini/Flat'   # 0\npotsdam_image_path_gable = '../input/potsdam-mini/potsdam-mini/Gable' # 1\npotsdam_image_path_hip = '../input/potsdam-mini/potsdam-mini/Hip'     # 2\n\n\n\nfor img_path in glob.glob(os.path.join(potsdam_image_path_flat, '*.tif')):\n    potsdam_image_paths_list.append(str(img_path)) \n    potsdam_image_labels.append(0)\n\nfor img_path in glob.glob(os.path.join(potsdam_image_path_gable, '*.tif')):\n    potsdam_image_paths_list.append(str(img_path))\n    potsdam_image_labels.append(1)\n\nfor img_path in glob.glob(os.path.join(potsdam_image_path_hip, '*.tif')):\n    potsdam_image_paths_list.append(str(img_path)) \n    potsdam_image_labels.append(2)\n    \npotsdam_image_paths_list.sort()\nassert(len(potsdam_image_paths_list) == 300 and len(potsdam_image_labels) == 300)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:05:36.363099Z","iopub.execute_input":"2022-04-13T17:05:36.363886Z","iopub.status.idle":"2022-04-13T17:05:36.459397Z","shell.execute_reply.started":"2022-04-13T17:05:36.363819Z","shell.execute_reply":"2022-04-13T17:05:36.458782Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"zipped_list = list(zip(potsdam_image_paths_list, potsdam_image_labels))\nrandom.shuffle(zipped_list)\npotsdam_image_paths_list, potsdam_image_labels = zip(*zipped_list)\npotsdam_image_paths_list, potsdam_image_labels = list(potsdam_image_paths_list), list(potsdam_image_labels)\n\nprint(potsdam_image_paths_list)\nprint(potsdam_image_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:05:36.461841Z","iopub.execute_input":"2022-04-13T17:05:36.462022Z","iopub.status.idle":"2022-04-13T17:05:36.467837Z","shell.execute_reply.started":"2022-04-13T17:05:36.461999Z","shell.execute_reply":"2022-04-13T17:05:36.467000Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"mini_image_paths_list = []\nmini_labels = []\n\nfor i in range(0,10,1):\n    mini_image_paths_list.append(potsdam_image_paths_list[i])\n    mini_labels.append(0)\n    \nfor i in range(100,110,1):\n    mini_image_paths_list.append(potsdam_image_paths_list[i])\n    mini_labels.append(1)\n    \nfor i in range(200,210,1):\n    mini_image_paths_list.append(potsdam_image_paths_list[i])\n    mini_labels.append(2)\n    \nprint(mini_image_paths_list)\nprint(mini_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:05:36.469333Z","iopub.execute_input":"2022-04-13T17:05:36.469851Z","iopub.status.idle":"2022-04-13T17:05:36.480244Z","shell.execute_reply.started":"2022-04-13T17:05:36.469753Z","shell.execute_reply":"2022-04-13T17:05:36.479415Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"zipped_list = list(zip(mini_image_paths_list, mini_labels))\nrandom.shuffle(zipped_list)\nmini_image_paths_list, mini_labels = zip(*zipped_list)\nmini_image_paths_list, mini_labels = list(mini_image_paths_list), list(mini_labels)\n\nprint(mini_image_paths_list)\nprint(mini_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:05:36.481710Z","iopub.execute_input":"2022-04-13T17:05:36.482002Z","iopub.status.idle":"2022-04-13T17:05:36.490169Z","shell.execute_reply.started":"2022-04-13T17:05:36.481967Z","shell.execute_reply":"2022-04-13T17:05:36.489420Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# train_X_potsdam = []\n# train_Y_potsdam = []\n# for i, img in enumerate(mini_image_paths_list):\n#     img = cv2.imread(img, cv2.IMREAD_COLOR)\n#     resized_img = cv2.resize(img,(256, 256), interpolation = cv2.INTER_CUBIC)\n#     train_X_potsdam.append(resized_img)\n    \n# train_Y_potsdam = mini_labels\n\ntrain_X_potsdam = []\ntrain_Y_potsdam = []\nfor i, img in enumerate(potsdam_image_paths_list):\n    img = cv2.imread(img, cv2.IMREAD_COLOR)\n    resized_img = cv2.resize(img,(256, 256), interpolation = cv2.INTER_CUBIC)\n    train_X_potsdam.append(resized_img)\n    \ntrain_Y_potsdam = potsdam_image_labels","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:05:36.491344Z","iopub.execute_input":"2022-04-13T17:05:36.491999Z","iopub.status.idle":"2022-04-13T17:05:39.367968Z","shell.execute_reply.started":"2022-04-13T17:05:36.491962Z","shell.execute_reply":"2022-04-13T17:05:39.367135Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train_X_potsdam = np.array(train_X_potsdam)\ntrain_Y_potsdam = np.array(train_Y_potsdam)\n\ntrain_X_potsdam = train_X_potsdam.astype('float32')\ntrain_X_potsdam /= 255.\ntrain_Y_potsdam = train_Y_potsdam.reshape(train_Y_potsdam.shape[0],1)\ntrain_Y_potsdam = to_categorical(train_Y_potsdam, num_classes = 3)\n\nprint(train_X_potsdam.shape, train_Y_potsdam.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:05:39.369502Z","iopub.execute_input":"2022-04-13T17:05:39.369786Z","iopub.status.idle":"2022-04-13T17:05:39.474834Z","shell.execute_reply.started":"2022-04-13T17:05:39.369746Z","shell.execute_reply":"2022-04-13T17:05:39.474045Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"### **Test Time Augmentation**","metadata":{}},{"cell_type":"code","source":"# make a prediction using test-time augmentation\ndef tta_prediction(datagen, model, image, n_examples):\n    # convert image into dataset\n    samples = expand_dims(image, 0)\n    # prepare iterator\n    it = datagen.flow(samples, batch_size=n_examples)\n    # make predictions for each augmented image\n    yhats = model.predict_generator(it, steps=n_examples, verbose=0)\n    # sum across predictions\n    summed = np.sum(yhats, axis=0)\n    # argmax across classes\n    return argmax(summed)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:05:39.477148Z","iopub.execute_input":"2022-04-13T17:05:39.477562Z","iopub.status.idle":"2022-04-13T17:05:39.483179Z","shell.execute_reply.started":"2022-04-13T17:05:39.477524Z","shell.execute_reply":"2022-04-13T17:05:39.482421Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# evaluate a model on a dataset using test-time augmentation\ndef tta_evaluate_model(model, test_X, test_Y):\n    # configure image data augmentation\n    datagen = ImageDataGenerator( rotation_range = 7,  # randomly rotate images in the range (degrees, 0 to 180)\n                                  width_shift_range = 0.10,  # randomly shift images horizontally (fraction of total width)\n                                  height_shift_range = 0.10,  # randomly shift images vertically (fraction of total height)\n                                  horizontal_flip = True,  # randomly flip images\n                                  vertical_flip = True,   # randomly flip images\n                                  fill_mode = 'reflect')\n    # define the number of augmented images to generate per test set image\n    n_examples_per_image = 5\n    yhats = list()\n    for i in range(len(test_X)):\n        # make augmented prediction\n        yhat = tta_prediction(datagen, model, test_X[i], n_examples_per_image)\n        # store for evaluation\n        yhats.append(yhat)\n    # calculate accuracy\n    print(yhats)\n    testY_labels = argmax(test_Y, axis=1)\n    acc = accuracy_score(testY_labels, yhats)\n    plot_confusion_matrix(testY_labels, yhats)\n    print_classification_report(testY_labels, yhats)\n    return acc, yhats","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:23:08.297177Z","iopub.execute_input":"2022-04-13T17:23:08.297442Z","iopub.status.idle":"2022-04-13T17:23:08.304718Z","shell.execute_reply.started":"2022-04-13T17:23:08.297415Z","shell.execute_reply":"2022-04-13T17:23:08.303947Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"### **CNN with RMS Prop**\n\n* Optimizer - RMS Prop\n* Learning Rate -0.0001\n* Batch size - 16\n* Epochs - 50","metadata":{}},{"cell_type":"code","source":"CNNmodel_RMS = Sequential()\n\nCNNmodel_RMS.add(Conv2D(64, (3, 3), padding='same',\n                 input_shape = train_X.shape[1:]))\nCNNmodel_RMS.add(Activation('relu'))\nCNNmodel_RMS.add(Conv2D(110, (3, 3)))\nCNNmodel_RMS.add(Activation('relu'))\nCNNmodel_RMS.add(MaxPooling2D(pool_size=(2, 2)))\nCNNmodel_RMS.add(Dropout(0.15))\n\nCNNmodel_RMS.add(Conv2D(84, (3, 3), padding='same'))\nCNNmodel_RMS.add(Activation('relu'))\nCNNmodel_RMS.add(Conv2D(84, (3, 3)))\nCNNmodel_RMS.add(Activation('relu'))\nCNNmodel_RMS.add(MaxPooling2D(pool_size=(2, 2)))\nCNNmodel_RMS.add(Dropout(0.20))\n\nCNNmodel_RMS.add(Conv2D(64, (3, 3), padding='same'))\nCNNmodel_RMS.add(Activation('relu'))\nCNNmodel_RMS.add(Conv2D(64, (3, 3)))\nCNNmodel_RMS.add(Activation('relu'))\nCNNmodel_RMS.add(MaxPooling2D(pool_size=(2, 2)))\nCNNmodel_RMS.add(Dropout(0.20))\n\nCNNmodel_RMS.add(Conv2D(32, (3, 3), padding='same'))\nCNNmodel_RMS.add(Activation('relu'))\nCNNmodel_RMS.add(Conv2D(32, (3, 3)))\nCNNmodel_RMS.add(Activation('relu'))\nCNNmodel_RMS.add(MaxPooling2D(pool_size=(2, 2)))\nCNNmodel_RMS.add(Dropout(0.20))\n\nCNNmodel_RMS.add(Flatten())\nCNNmodel_RMS.add(Dense(1024))\nCNNmodel_RMS.add(Activation('relu'))\nCNNmodel_RMS.add(Dense(3))\nCNNmodel_RMS.add(Activation('softmax'))\n\nCNNmodel_RMS.summary()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:06:29.062053Z","iopub.execute_input":"2022-04-13T17:06:29.062523Z","iopub.status.idle":"2022-04-13T17:06:31.573504Z","shell.execute_reply.started":"2022-04-13T17:06:29.062486Z","shell.execute_reply":"2022-04-13T17:06:31.572810Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# checkpoint: save best model during the training \nfilepath = \"./CNN-RMSProp-50epochs\"\ncheckpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose = 0, save_best_only = True, mode = 'max')\ncallbacks_list = [checkpoint]\n\n# initiate RMSprop optimizer\nopt = keras.optimizers.RMSprop(learning_rate = 0.0001, decay = 1e-7)\n\n# Let's train the model using RMSprop\nCNNmodel_RMS.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['acc']) ","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:06:31.574818Z","iopub.execute_input":"2022-04-13T17:06:31.575163Z","iopub.status.idle":"2022-04-13T17:06:31.591698Z","shell.execute_reply.started":"2022-04-13T17:06:31.575127Z","shell.execute_reply":"2022-04-13T17:06:31.590902Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"history_CNN_RMS = CNNmodel_RMS.fit(data_generation.flow(train_X, train_Y, batch_size = 16),\n                                steps_per_epoch = train_X.shape[0] // 16,\n                                epochs = 50,\n                                validation_data = (val_X, val_Y),\n                                callbacks = [callbacks_list])","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:06:32.571751Z","iopub.execute_input":"2022-04-13T17:06:32.572003Z","iopub.status.idle":"2022-04-13T17:21:50.166801Z","shell.execute_reply.started":"2022-04-13T17:06:32.571973Z","shell.execute_reply":"2022-04-13T17:21:50.166019Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"plot_accuracy_loss(history_CNN_RMS)\npred_labels, test_labels = make_predictions(CNNmodel_RMS, test_X, test_Y)\nprint(\"Predictions: \", pred_labels)\nprint(\"Actual: \", test_labels)\nplot_confusion_matrix(test_labels, pred_labels)\nprint_classification_report(test_labels, pred_labels)\nplot_AUC_ROC(CNNmodel_RMS, test_X, test_Y)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:22:11.361395Z","iopub.execute_input":"2022-04-13T17:22:11.361667Z","iopub.status.idle":"2022-04-13T17:22:13.158586Z","shell.execute_reply.started":"2022-04-13T17:22:11.361636Z","shell.execute_reply":"2022-04-13T17:22:13.157914Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"### **Testing CNN model on PotsDam dataset**","metadata":{}},{"cell_type":"code","source":"CNNmodel_RMS = tf.keras.models.load_model('./CNN-RMSProp-50epochs')\ntest_loss = CNNmodel_RMS.evaluate(train_X_potsdam, train_Y_potsdam)\npredictions = CNNmodel_RMS.predict(train_X_potsdam)\npred_labels = np.argmax(predictions, axis = 1)\ntest_labels = np.argmax(train_Y_potsdam, axis = 1)\nprint(pred_labels)\nprint(test_labels)\nprint(test_loss)\nprint_classification_report(test_labels, pred_labels)\nplot_confusion_matrix(test_labels, pred_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:22:14.024272Z","iopub.execute_input":"2022-04-13T17:22:14.024543Z","iopub.status.idle":"2022-04-13T17:22:19.741633Z","shell.execute_reply.started":"2022-04-13T17:22:14.024511Z","shell.execute_reply":"2022-04-13T17:22:19.740816Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"acc, yhats = tta_evaluate_model(CNNmodel_RMS, train_X_potsdam, train_Y_potsdam)\nprint(acc)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:23:14.717545Z","iopub.execute_input":"2022-04-13T17:23:14.718079Z","iopub.status.idle":"2022-04-13T17:23:35.925374Z","shell.execute_reply.started":"2022-04-13T17:23:14.718018Z","shell.execute_reply":"2022-04-13T17:23:35.924679Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"### **ResNet50**\n\n* Optimizer - RMSProp\n* Learning rate - 0.00001\n* Epochs - 50\n* Batch size- 8","metadata":{}},{"cell_type":"code","source":"ResNet50_model = keras.applications.resnet50.ResNet50()\nimage_size = 256\ninput_shape = (image_size, image_size, 3)\n\npre_trained_model_finetuning = ResNet50(input_shape=input_shape, include_top=False, weights=\"imagenet\")\npre_trained_model_finetuning.trainable = True","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:23:52.691951Z","iopub.execute_input":"2022-04-13T17:23:52.692239Z","iopub.status.idle":"2022-04-13T17:23:56.400794Z","shell.execute_reply.started":"2022-04-13T17:23:52.692208Z","shell.execute_reply":"2022-04-13T17:23:56.400076Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"last_layer = pre_trained_model_finetuning.get_layer('conv5_block3_out')\nlast_output = last_layer.output\n\nx = GlobalMaxPooling2D()(last_output)\nx = Dense(64, activation = 'relu')(x)\nx = Dropout(0.2)(x)\n\nx = Dense(128, activation = 'relu')(x)\nx = Dropout(0.2)(x)\n\nx = Dense(256, activation = 'relu')(x)\nx = Dropout(0.2)(x)\n\nx = Dense(512, activation = 'relu')(x)\nx = Dropout(0.2)(x)\n\nx = keras.layers.Dense(3, activation = 'softmax')(x)\n\nResNet50_finetuning_bs8 = Model(pre_trained_model_finetuning.input, x)\n\nResNet50_finetuning_bs8.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:23:56.402286Z","iopub.execute_input":"2022-04-13T17:23:56.402522Z","iopub.status.idle":"2022-04-13T17:23:56.552022Z","shell.execute_reply.started":"2022-04-13T17:23:56.402489Z","shell.execute_reply":"2022-04-13T17:23:56.551390Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# checkpoint: save best model during the training \nfilepath = \"./ResNet50-50epochs-bs8\"\ncheckpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')\ncallbacks_list = [checkpoint]\n\n# initiate RMSprop optimizer\nopt = keras.optimizers.RMSprop(learning_rate = 0.00001, decay = 1e-7)\n\n# Let's train the model using RMSprop\nResNet50_finetuning_bs8.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['acc']) ","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:23:56.553736Z","iopub.execute_input":"2022-04-13T17:23:56.553929Z","iopub.status.idle":"2022-04-13T17:23:56.633413Z","shell.execute_reply.started":"2022-04-13T17:23:56.553904Z","shell.execute_reply":"2022-04-13T17:23:56.632528Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"history_ResNet50_finetuning_bs8 = ResNet50_finetuning_bs8.fit(data_generation.flow(train_X, train_Y, batch_size = 8),\n                                steps_per_epoch = train_X.shape[0] // 8,\n                                epochs = 50,\n                                validation_data = (val_X, val_Y),\n                                callbacks = [callbacks_list])","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:23:56.637371Z","iopub.execute_input":"2022-04-13T17:23:56.637697Z","iopub.status.idle":"2022-04-13T17:49:02.421542Z","shell.execute_reply.started":"2022-04-13T17:23:56.637590Z","shell.execute_reply":"2022-04-13T17:49:02.420748Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"plot_accuracy_loss(history_ResNet50_finetuning_bs8)\npred_labels, test_labels = make_predictions(ResNet50_finetuning_bs8, test_X, test_Y)\nprint(\"Predictions: \", pred_labels)\nprint(\"Actual: \", test_labels)\nplot_confusion_matrix(test_labels, pred_labels)\nprint_classification_report(test_labels, pred_labels)\nplot_AUC_ROC(ResNet50_finetuning_bs8, test_X, test_Y)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:49:02.423207Z","iopub.execute_input":"2022-04-13T17:49:02.423469Z","iopub.status.idle":"2022-04-13T17:49:05.207562Z","shell.execute_reply.started":"2022-04-13T17:49:02.423424Z","shell.execute_reply":"2022-04-13T17:49:05.206894Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"### **ResNet testing on PotsDam Dataset**","metadata":{}},{"cell_type":"code","source":"ResNet50_finetuning_bs8 = tf.keras.models.load_model('./ResNet50-50epochs-bs8')\ntest_loss = ResNet50_finetuning_bs8.evaluate(train_X_potsdam, train_Y_potsdam)\npredictions = ResNet50_finetuning_bs8.predict(train_X_potsdam)\npred_labels = np.argmax(predictions, axis = 1)\ntest_labels = np.argmax(train_Y_potsdam, axis = 1)\nprint(pred_labels)\nprint(test_labels)\nprint(test_loss)\nprint_classification_report(test_labels, pred_labels)\nplot_confusion_matrix(test_labels, pred_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:49:05.208964Z","iopub.execute_input":"2022-04-13T17:49:05.209413Z","iopub.status.idle":"2022-04-13T17:49:20.312583Z","shell.execute_reply.started":"2022-04-13T17:49:05.209377Z","shell.execute_reply":"2022-04-13T17:49:20.311903Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"acc, yhats = tta_evaluate_model(ResNet50_finetuning_bs8, train_X_potsdam, train_Y_potsdam)\nprint(acc)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:49:20.313824Z","iopub.execute_input":"2022-04-13T17:49:20.314550Z","iopub.status.idle":"2022-04-13T17:49:45.356485Z","shell.execute_reply.started":"2022-04-13T17:49:20.314510Z","shell.execute_reply":"2022-04-13T17:49:45.355738Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"### **EfficientNetB4 with finetuning**\n\n* Optimizer - RMSProp\n* Learning rate - 0.00001\n* Batch size - 16\n* Epochs - 50","metadata":{}},{"cell_type":"code","source":"image_size = 256\ninput_shape = (image_size, image_size, 3)\nEfficientNetModel = EfficientNetB4(input_shape=input_shape, include_top = False, weights='imagenet')\nEfficientNetModel.trainable = True","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:49:45.357758Z","iopub.execute_input":"2022-04-13T17:49:45.358114Z","iopub.status.idle":"2022-04-13T17:49:48.820373Z","shell.execute_reply.started":"2022-04-13T17:49:45.358058Z","shell.execute_reply":"2022-04-13T17:49:48.819605Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"last_layer = EfficientNetModel.get_layer('top_bn')\nlast_output = last_layer.output\n\nx = GlobalMaxPooling2D()(last_output)\nx = Dense(64, activation = 'relu')(x)\nx = Dropout(0.2)(x)\n\nx = Dense(128, activation = 'relu')(x)\nx = Dropout(0.2)(x)\n\nx = Dense(256, activation = 'relu')(x)\nx = Dropout(0.2)(x)\n\nx = Dense(512, activation = 'relu')(x)\nx = Dropout(0.2)(x)\n\nx = keras.layers.Dense(3, activation = 'softmax')(x)\n\nEfficientNetB4_finetuning_RMS_bs16 = Model(EfficientNetModel.input, x)\n\nEfficientNetB4_finetuning_RMS_bs16.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:49:48.821695Z","iopub.execute_input":"2022-04-13T17:49:48.821938Z","iopub.status.idle":"2022-04-13T17:49:49.122640Z","shell.execute_reply.started":"2022-04-13T17:49:48.821894Z","shell.execute_reply":"2022-04-13T17:49:49.121987Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# checkpoint: save best model during the training \nfilepath = \"./EfficientNetB4-50epochs-bs16-RMS\"\ncheckpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')\ncallbacks_list = [checkpoint]\n\n# initiate RMS optimizer\nopt = keras.optimizers.RMSprop(learning_rate = 0.00001, decay = 1e-7)\n\n# Let's train the model using RMS\nEfficientNetB4_finetuning_RMS_bs16.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['acc'])  ","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:49:49.125514Z","iopub.execute_input":"2022-04-13T17:49:49.126010Z","iopub.status.idle":"2022-04-13T17:49:49.146487Z","shell.execute_reply.started":"2022-04-13T17:49:49.125971Z","shell.execute_reply":"2022-04-13T17:49:49.145841Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"history_EfficientNetB4_finetuning_RMS_bs16 = EfficientNetB4_finetuning_RMS_bs16.fit(data_generation.flow(train_X, train_Y, batch_size = 16),\n                                steps_per_epoch = train_X.shape[0] // 16,\n                                epochs = 50,\n                                validation_data = (val_X, val_Y),\n                                callbacks = [callbacks_list])","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:49:49.147789Z","iopub.execute_input":"2022-04-13T17:49:49.148045Z","iopub.status.idle":"2022-04-13T18:34:08.358269Z","shell.execute_reply.started":"2022-04-13T17:49:49.148013Z","shell.execute_reply":"2022-04-13T18:34:08.357546Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"plot_accuracy_loss(history_EfficientNetB4_finetuning_RMS_bs16)\npred_labels, test_labels = make_predictions(EfficientNetB4_finetuning_RMS_bs16, test_X, test_Y)\nprint(\"Predictions: \", pred_labels)\nprint(\"Actual: \", test_labels)\nplot_confusion_matrix(test_labels, pred_labels)\nprint_classification_report(test_labels, pred_labels)\nplot_AUC_ROC(EfficientNetB4_finetuning_RMS_bs16, test_X, test_Y)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T18:34:08.360007Z","iopub.execute_input":"2022-04-13T18:34:08.360264Z","iopub.status.idle":"2022-04-13T18:34:13.843649Z","shell.execute_reply.started":"2022-04-13T18:34:08.360226Z","shell.execute_reply":"2022-04-13T18:34:13.842901Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"### **Testing EfficientNetB4-RMS Prop on PotsDam dataset**","metadata":{}},{"cell_type":"code","source":"EfficientNetB4_finetuning_RMS_bs16 = tf.keras.models.load_model('./EfficientNetB4-50epochs-bs16-RMS')\ntest_loss = EfficientNetB4_finetuning_RMS_bs16.evaluate(train_X_potsdam, train_Y_potsdam)\npredictions = EfficientNetB4_finetuning_RMS_bs16.predict(train_X_potsdam)\npred_labels = np.argmax(predictions, axis = 1)\ntest_labels = np.argmax(train_Y_potsdam, axis = 1)\nprint(pred_labels)\nprint(test_labels)\nprint(test_loss)\nprint_classification_report(test_labels, pred_labels)\nplot_confusion_matrix(test_labels, pred_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T18:34:13.845048Z","iopub.execute_input":"2022-04-13T18:34:13.845307Z","iopub.status.idle":"2022-04-13T18:34:49.320454Z","shell.execute_reply.started":"2022-04-13T18:34:13.845273Z","shell.execute_reply":"2022-04-13T18:34:49.319056Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"acc, yhats = tta_evaluate_model(EfficientNetB4_finetuning_RMS_bs16, train_X_potsdam, train_Y_potsdam)\nprint(acc)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T18:34:49.321853Z","iopub.execute_input":"2022-04-13T18:34:49.322176Z","iopub.status.idle":"2022-04-13T18:35:21.533755Z","shell.execute_reply.started":"2022-04-13T18:34:49.322136Z","shell.execute_reply":"2022-04-13T18:35:21.533086Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"### **EfficientNetB4**\n\n* Optimizer - Adam\n* Learning rate - 0.00001\n* Batch size - 16\n* Epochs - 50","metadata":{}},{"cell_type":"code","source":"image_size = 256\ninput_shape = (image_size, image_size, 3)\nEfficientNetModel = EfficientNetB4(input_shape=input_shape, include_top = False, weights='imagenet')\nEfficientNetModel.trainable = True","metadata":{"execution":{"iopub.status.busy":"2022-04-13T18:35:21.535167Z","iopub.execute_input":"2022-04-13T18:35:21.535408Z","iopub.status.idle":"2022-04-13T18:35:24.445944Z","shell.execute_reply.started":"2022-04-13T18:35:21.535374Z","shell.execute_reply":"2022-04-13T18:35:24.445199Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"last_layer = EfficientNetModel.get_layer('top_bn')\nlast_output = last_layer.output\n\nx = GlobalMaxPooling2D()(last_output)\nx = Dense(64, activation = 'relu')(x)\nx = Dropout(0.2)(x)\n\nx = Dense(128, activation = 'relu')(x)\nx = Dropout(0.2)(x)\n\nx = Dense(256, activation = 'relu')(x)\nx = Dropout(0.2)(x)\n\nx = Dense(512, activation = 'relu')(x)\nx = Dropout(0.2)(x)\n\nx = keras.layers.Dense(3, activation = 'softmax')(x)\n\nEfficientNetB4_finetuning_Adam_bs16 = Model(EfficientNetModel.input, x)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T18:35:24.447229Z","iopub.execute_input":"2022-04-13T18:35:24.447476Z","iopub.status.idle":"2022-04-13T18:35:24.523933Z","shell.execute_reply.started":"2022-04-13T18:35:24.447443Z","shell.execute_reply":"2022-04-13T18:35:24.523317Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# checkpoint: save best model during the training \nfilepath = \"./EfficientNetB4-50epochs-bs16-Adam\"\ncheckpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')\ncallbacks_list = [checkpoint]\n\n# initiate RMS optimizer\nopt = keras.optimizers.Adam(learning_rate = 0.00001, decay = 1e-7)\n\n# Let's train the model using Adam\nEfficientNetB4_finetuning_Adam_bs16.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['acc'])  ","metadata":{"execution":{"iopub.status.busy":"2022-04-13T18:35:24.525282Z","iopub.execute_input":"2022-04-13T18:35:24.525550Z","iopub.status.idle":"2022-04-13T18:35:24.545228Z","shell.execute_reply.started":"2022-04-13T18:35:24.525514Z","shell.execute_reply":"2022-04-13T18:35:24.544603Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"history_EfficientNetB4_finetuning_Adam_bs16 = EfficientNetB4_finetuning_Adam_bs16.fit(data_generation.flow(train_X, train_Y, batch_size = 16),\n                                steps_per_epoch = train_X.shape[0] // 16,\n                                epochs = 50,\n                                validation_data = (val_X, val_Y),\n                                callbacks = [callbacks_list])","metadata":{"execution":{"iopub.status.busy":"2022-04-13T18:35:24.546314Z","iopub.execute_input":"2022-04-13T18:35:24.546563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_accuracy_loss(history_EfficientNetB4_finetuning_Adam_bs16)\npred_labels, test_labels = make_predictions(EfficientNetB4_finetuning_Adam_bs16, test_X, test_Y)\nprint(\"Predictions: \", pred_labels)\nprint(\"Actual: \", test_labels)\nplot_confusion_matrix(test_labels, pred_labels)\nprint_classification_report(test_labels, pred_labels)\nplot_AUC_ROC(EfficientNetB4_finetuning_Adam_bs16, test_X, test_Y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Testing EfficientNetB4-Adam on PotsDam dataset**","metadata":{}},{"cell_type":"code","source":"EfficientNetB4_finetuning_Adam_bs16 = tf.keras.models.load_model('./EfficientNetB4-50epochs-bs16-Adam')\ntest_loss = EfficientNetB4_finetuning_Adam_bs16.evaluate(train_X_potsdam, train_Y_potsdam)\npredictions = EfficientNetB4_finetuning_Adam_bs16.predict(train_X_potsdam)\npred_labels = np.argmax(predictions, axis = 1)\ntest_labels = np.argmax(train_Y_potsdam, axis = 1)\nprint(pred_labels)\nprint(test_labels)\nprint(test_loss)\nprint_classification_report(test_labels, pred_labels)\nplot_confusion_matrix(test_labels, pred_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc, yhats = tta_evaluate_model(EfficientNetB4_finetuning_Adam_bs16, train_X_potsdam, train_Y_potsdam)\nprint(acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **VGG16**\n\n* Optimizer - RMSProp\n* Learning rate - 0.00001\n* Batch size - 4\n* Epochs - 50","metadata":{}},{"cell_type":"code","source":"image_size = 256\ninput_shape = (image_size, image_size, 3)\n\npre_trained_model_VGG = VGG16(input_shape=input_shape, include_top=False, weights=\"imagenet\")\npre_trained_model_VGG.trainable = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"last_layer = pre_trained_model_VGG.get_layer('block5_pool')\nlast_output = last_layer.output\n\nx = GlobalMaxPooling2D()(last_output)\nx = Dense(64, activation = 'relu')(x)\nx = Dropout(0.2)(x)\n\nx = Dense(128, activation = 'relu')(x)\nx = Dropout(0.2)(x)\n\nx = Dense(256, activation = 'relu')(x)\nx = Dropout(0.2)(x)\n\nx = Dense(512, activation = 'relu')(x)\nx = Dropout(0.2)(x)\n\nx = keras.layers.Dense(3, activation = 'softmax')(x)\n\nVGG16_finetuning_RMS_bs4 = Model(pre_trained_model_VGG.input, x)\n\nVGG16_finetuning_RMS_bs4.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checkpoint: save best model during the training \nfilepath = \"./VGG16-50epochs-RMS-bs4\"\ncheckpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')\ncallbacks_list = [checkpoint]\n\n# initiate RMSProp optimizer\nopt = keras.optimizers.RMSprop(learning_rate = 0.00001, decay = 1e-7)\n\n# Let's train the model using RMSProp\nVGG16_finetuning_RMS_bs4.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['acc'])  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_VGG16_finetuning_RMS_bs4 = VGG16_finetuning_RMS_bs4.fit(data_generation.flow(train_X, train_Y, batch_size = 4),\n                                steps_per_epoch = train_X.shape[0] // 4,\n                                epochs = 50,\n                                validation_data = (val_X, val_Y),\n                                callbacks = [callbacks_list])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_accuracy_loss(history_VGG16_finetuning_RMS_bs4)\npred_labels, test_labels = make_predictions(VGG16_finetuning_RMS_bs4, test_X, test_Y)\nprint(\"Predictions: \", pred_labels)\nprint(\"Actual: \", test_labels)\nplot_confusion_matrix(test_labels, pred_labels)\nprint_classification_report(test_labels, pred_labels)\nplot_AUC_ROC(VGG16_finetuning_RMS_bs4, test_X, test_Y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Testing VGG16 on PotsDam dataset**","metadata":{}},{"cell_type":"code","source":"VGG16_finetuning_RMS_bs4 = tf.keras.models.load_model('./VGG16-50epochs-RMS-bs4')\ntest_loss = VGG16_finetuning_RMS_bs4.evaluate(train_X_potsdam, train_Y_potsdam)\npredictions = VGG16_finetuning_RMS_bs4.predict(train_X_potsdam)\npred_labels = np.argmax(predictions, axis = 1)\ntest_labels = np.argmax(train_Y_potsdam, axis = 1)\nprint(pred_labels)\nprint(test_labels)\nprint(test_loss)\nprint_classification_report(test_labels, pred_labels)\nplot_confusion_matrix(test_labels, pred_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc, yhats = tta_evaluate_model(VGG16_finetuning_RMS_bs4, train_X_potsdam, train_Y_potsdam)\nprint(acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}